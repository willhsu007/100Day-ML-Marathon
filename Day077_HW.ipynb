{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Day077_HW.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjp5MDJlOA1p",
        "colab_type": "text"
      },
      "source": [
        "## Work\n",
        "1. 請將 Epoch 加到 500 個，並觀察 learning curve 的走勢\n",
        "2. 請將 Optimizer 換成 SGD，並觀察 learning curve 的走勢"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWXuZewBOA1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import keras\n",
        "\n",
        "# 本作業可以不需使用 GPU, 將 GPU 設定為 \"無\" (若有 GPU 且想開啟，可設為 \"0\")\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeJSJrT-OA1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 從 Keras 的內建功能中，取得 train 與 test 資料集\n",
        "train, test = keras.datasets.cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_UWxjG3OA1u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 將 X 與 Y 獨立放進變數\n",
        "x_train, y_train = train\n",
        "x_test, y_test = test\n",
        "# 資料前處理 - 標準化\n",
        "x_train = x_train / 255.\n",
        "x_test = x_test / 255.\n",
        "\n",
        "# 將資料從圖形 (RGB) 轉為向量 (Single Vector)\n",
        "x_train = x_train.reshape((len(x_train), -1))\n",
        "x_test = x_test.reshape((len(x_test), -1))\n",
        "\n",
        "# 將目標轉為 one-hot encoding\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85q0mKK8OA1x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_mlp():\n",
        "    input_layer = keras.layers.Input([x_train.shape[-1]])\n",
        "    x = keras.layers.Dense(units=512, activation=\"relu\")(input_layer)\n",
        "    x = keras.layers.Dense(units=256, activation=\"relu\")(x)\n",
        "    x = keras.layers.Dense(units=128, activation=\"relu\")(x)\n",
        "    out = keras.layers.Dense(units=10, activation=\"softmax\")(x)\n",
        "    \n",
        "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMUvapnuOA1z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "outputId": "fa52895d-7047-46b7-ea3b-9a5e42aaaa73"
      },
      "source": [
        "model = build_mlp()\n",
        "# 用 Keras 內建方法檢視模型各層參數量\n",
        "model.summary()\n",
        "\n",
        "optimizer = keras.optimizers.SGD(lr=0.001)\n",
        "model.compile(loss=\"binary_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               1573376   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,738,890\n",
            "Trainable params: 1,738,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "WrE8SZEFOA10",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "203d317f-2b45-4189-bc4c-0d4ddebb8f0d"
      },
      "source": [
        "model.fit(x_train, y_train, \n",
        "          epochs=500, \n",
        "          batch_size=256, \n",
        "          validation_data=(x_test, y_test), \n",
        "          shuffle=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/500\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 0.3286 - acc: 0.9000 - val_loss: 0.3260 - val_acc: 0.9000\n",
            "Epoch 2/500\n",
            "50000/50000 [==============================] - 10s 202us/step - loss: 0.3244 - acc: 0.9000 - val_loss: 0.3231 - val_acc: 0.9000\n",
            "Epoch 3/500\n",
            "50000/50000 [==============================] - 10s 197us/step - loss: 0.3221 - acc: 0.9000 - val_loss: 0.3212 - val_acc: 0.9000\n",
            "Epoch 4/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 0.3204 - acc: 0.9000 - val_loss: 0.3198 - val_acc: 0.9000\n",
            "Epoch 5/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 0.3191 - acc: 0.9000 - val_loss: 0.3185 - val_acc: 0.9000\n",
            "Epoch 6/500\n",
            "50000/50000 [==============================] - 10s 202us/step - loss: 0.3180 - acc: 0.9000 - val_loss: 0.3174 - val_acc: 0.9000\n",
            "Epoch 7/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 0.3169 - acc: 0.9000 - val_loss: 0.3164 - val_acc: 0.9000\n",
            "Epoch 8/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 0.3159 - acc: 0.9000 - val_loss: 0.3154 - val_acc: 0.9000\n",
            "Epoch 9/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 0.3149 - acc: 0.9000 - val_loss: 0.3145 - val_acc: 0.9000\n",
            "Epoch 10/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 0.3140 - acc: 0.9000 - val_loss: 0.3136 - val_acc: 0.9000\n",
            "Epoch 11/500\n",
            "50000/50000 [==============================] - 10s 210us/step - loss: 0.3131 - acc: 0.9000 - val_loss: 0.3127 - val_acc: 0.9000\n",
            "Epoch 12/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.3122 - acc: 0.9000 - val_loss: 0.3118 - val_acc: 0.9000\n",
            "Epoch 13/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 0.3114 - acc: 0.9000 - val_loss: 0.3110 - val_acc: 0.9000\n",
            "Epoch 14/500\n",
            "50000/50000 [==============================] - 10s 204us/step - loss: 0.3106 - acc: 0.9000 - val_loss: 0.3102 - val_acc: 0.9000\n",
            "Epoch 15/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 0.3098 - acc: 0.9000 - val_loss: 0.3094 - val_acc: 0.9000\n",
            "Epoch 16/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 0.3091 - acc: 0.9000 - val_loss: 0.3087 - val_acc: 0.9000\n",
            "Epoch 17/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 0.3083 - acc: 0.9000 - val_loss: 0.3080 - val_acc: 0.9000\n",
            "Epoch 18/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 0.3076 - acc: 0.9000 - val_loss: 0.3073 - val_acc: 0.9000\n",
            "Epoch 19/500\n",
            "50000/50000 [==============================] - 10s 201us/step - loss: 0.3069 - acc: 0.9000 - val_loss: 0.3066 - val_acc: 0.9000\n",
            "Epoch 20/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 0.3063 - acc: 0.9000 - val_loss: 0.3059 - val_acc: 0.9000\n",
            "Epoch 21/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 0.3056 - acc: 0.9000 - val_loss: 0.3053 - val_acc: 0.9000\n",
            "Epoch 22/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 0.3050 - acc: 0.9000 - val_loss: 0.3046 - val_acc: 0.9000\n",
            "Epoch 23/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 0.3044 - acc: 0.9000 - val_loss: 0.3040 - val_acc: 0.9000\n",
            "Epoch 24/500\n",
            "50000/50000 [==============================] - 10s 204us/step - loss: 0.3037 - acc: 0.9000 - val_loss: 0.3034 - val_acc: 0.9000\n",
            "Epoch 25/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 0.3031 - acc: 0.9000 - val_loss: 0.3028 - val_acc: 0.9000\n",
            "Epoch 26/500\n",
            "50000/50000 [==============================] - 10s 202us/step - loss: 0.3025 - acc: 0.9000 - val_loss: 0.3023 - val_acc: 0.9000\n",
            "Epoch 27/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 0.3020 - acc: 0.9000 - val_loss: 0.3017 - val_acc: 0.9000\n",
            "Epoch 28/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 0.3014 - acc: 0.9000 - val_loss: 0.3011 - val_acc: 0.9000\n",
            "Epoch 29/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 0.3009 - acc: 0.9000 - val_loss: 0.3006 - val_acc: 0.9000\n",
            "Epoch 30/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 0.3003 - acc: 0.9000 - val_loss: 0.3001 - val_acc: 0.9000\n",
            "Epoch 31/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 0.2998 - acc: 0.9000 - val_loss: 0.2995 - val_acc: 0.9000\n",
            "Epoch 32/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 0.2993 - acc: 0.9000 - val_loss: 0.2990 - val_acc: 0.9000\n",
            "Epoch 33/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 0.2988 - acc: 0.9000 - val_loss: 0.2985 - val_acc: 0.9000\n",
            "Epoch 34/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 0.2983 - acc: 0.9000 - val_loss: 0.2980 - val_acc: 0.9000\n",
            "Epoch 35/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 0.2978 - acc: 0.9000 - val_loss: 0.2975 - val_acc: 0.9000\n",
            "Epoch 36/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 0.2973 - acc: 0.9000 - val_loss: 0.2971 - val_acc: 0.9000\n",
            "Epoch 37/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 0.2968 - acc: 0.9000 - val_loss: 0.2966 - val_acc: 0.9000\n",
            "Epoch 38/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 0.2964 - acc: 0.9000 - val_loss: 0.2961 - val_acc: 0.9000\n",
            "Epoch 39/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 0.2960 - acc: 0.9000 - val_loss: 0.2957 - val_acc: 0.9000\n",
            "Epoch 40/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 0.2955 - acc: 0.9000 - val_loss: 0.2953 - val_acc: 0.9000\n",
            "Epoch 41/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 0.2951 - acc: 0.9000 - val_loss: 0.2949 - val_acc: 0.9000\n",
            "Epoch 42/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 0.2947 - acc: 0.9000 - val_loss: 0.2945 - val_acc: 0.9000\n",
            "Epoch 43/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 0.2943 - acc: 0.9000 - val_loss: 0.2941 - val_acc: 0.9000\n",
            "Epoch 44/500\n",
            "50000/50000 [==============================] - 10s 202us/step - loss: 0.2939 - acc: 0.9000 - val_loss: 0.2937 - val_acc: 0.9000\n",
            "Epoch 45/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 0.2935 - acc: 0.9000 - val_loss: 0.2933 - val_acc: 0.9000\n",
            "Epoch 46/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 0.2931 - acc: 0.9000 - val_loss: 0.2929 - val_acc: 0.9001\n",
            "Epoch 47/500\n",
            "50000/50000 [==============================] - 10s 201us/step - loss: 0.2928 - acc: 0.9000 - val_loss: 0.2925 - val_acc: 0.9001\n",
            "Epoch 48/500\n",
            "50000/50000 [==============================] - 10s 200us/step - loss: 0.2924 - acc: 0.9001 - val_loss: 0.2922 - val_acc: 0.9001\n",
            "Epoch 49/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 0.2920 - acc: 0.9001 - val_loss: 0.2918 - val_acc: 0.9001\n",
            "Epoch 50/500\n",
            "50000/50000 [==============================] - 11s 210us/step - loss: 0.2917 - acc: 0.9001 - val_loss: 0.2915 - val_acc: 0.9001\n",
            "Epoch 51/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 0.2913 - acc: 0.9001 - val_loss: 0.2911 - val_acc: 0.9001\n",
            "Epoch 52/500\n",
            "50000/50000 [==============================] - 10s 201us/step - loss: 0.2910 - acc: 0.9001 - val_loss: 0.2908 - val_acc: 0.9002\n",
            "Epoch 53/500\n",
            "50000/50000 [==============================] - 12s 237us/step - loss: 0.2907 - acc: 0.9001 - val_loss: 0.2905 - val_acc: 0.9002\n",
            "Epoch 54/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 0.2903 - acc: 0.9002 - val_loss: 0.2902 - val_acc: 0.9002\n",
            "Epoch 55/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 0.2900 - acc: 0.9002 - val_loss: 0.2898 - val_acc: 0.9002\n",
            "Epoch 56/500\n",
            "50000/50000 [==============================] - 10s 210us/step - loss: 0.2897 - acc: 0.9002 - val_loss: 0.2895 - val_acc: 0.9003\n",
            "Epoch 57/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 0.2894 - acc: 0.9002 - val_loss: 0.2892 - val_acc: 0.9004\n",
            "Epoch 58/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 0.2891 - acc: 0.9003 - val_loss: 0.2889 - val_acc: 0.9004\n",
            "Epoch 59/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 0.2888 - acc: 0.9003 - val_loss: 0.2886 - val_acc: 0.9005\n",
            "Epoch 60/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 0.2885 - acc: 0.9003 - val_loss: 0.2883 - val_acc: 0.9005\n",
            "Epoch 61/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 0.2882 - acc: 0.9004 - val_loss: 0.2880 - val_acc: 0.9005\n",
            "Epoch 62/500\n",
            "50000/50000 [==============================] - 11s 210us/step - loss: 0.2879 - acc: 0.9004 - val_loss: 0.2878 - val_acc: 0.9005\n",
            "Epoch 63/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 0.2876 - acc: 0.9004 - val_loss: 0.2875 - val_acc: 0.9006\n",
            "Epoch 64/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 0.2873 - acc: 0.9004 - val_loss: 0.2872 - val_acc: 0.9006\n",
            "Epoch 65/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 0.2870 - acc: 0.9005 - val_loss: 0.2869 - val_acc: 0.9006\n",
            "Epoch 66/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 0.2868 - acc: 0.9005 - val_loss: 0.2867 - val_acc: 0.9007\n",
            "Epoch 67/500\n",
            "50000/50000 [==============================] - 10s 210us/step - loss: 0.2865 - acc: 0.9005 - val_loss: 0.2864 - val_acc: 0.9006\n",
            "Epoch 68/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 0.2862 - acc: 0.9005 - val_loss: 0.2861 - val_acc: 0.9007\n",
            "Epoch 69/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 0.2860 - acc: 0.9005 - val_loss: 0.2859 - val_acc: 0.9007\n",
            "Epoch 70/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 0.2857 - acc: 0.9006 - val_loss: 0.2856 - val_acc: 0.9008\n",
            "Epoch 71/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 0.2854 - acc: 0.9006 - val_loss: 0.2854 - val_acc: 0.9008\n",
            "Epoch 72/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 0.2852 - acc: 0.9006 - val_loss: 0.2851 - val_acc: 0.9008\n",
            "Epoch 73/500\n",
            "50000/50000 [==============================] - 11s 210us/step - loss: 0.2849 - acc: 0.9006 - val_loss: 0.2849 - val_acc: 0.9008\n",
            "Epoch 74/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 0.2847 - acc: 0.9007 - val_loss: 0.2846 - val_acc: 0.9009\n",
            "Epoch 75/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 0.2844 - acc: 0.9007 - val_loss: 0.2844 - val_acc: 0.9009\n",
            "Epoch 76/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 0.2842 - acc: 0.9008 - val_loss: 0.2842 - val_acc: 0.9009\n",
            "Epoch 77/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 0.2840 - acc: 0.9008 - val_loss: 0.2839 - val_acc: 0.9010\n",
            "Epoch 78/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 0.2837 - acc: 0.9008 - val_loss: 0.2837 - val_acc: 0.9010\n",
            "Epoch 79/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 0.2835 - acc: 0.9008 - val_loss: 0.2835 - val_acc: 0.9011\n",
            "Epoch 80/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 0.2833 - acc: 0.9009 - val_loss: 0.2832 - val_acc: 0.9011\n",
            "Epoch 81/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 0.2830 - acc: 0.9009 - val_loss: 0.2830 - val_acc: 0.9012\n",
            "Epoch 82/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 0.2828 - acc: 0.9009 - val_loss: 0.2828 - val_acc: 0.9012\n",
            "Epoch 83/500\n",
            "50000/50000 [==============================] - 11s 210us/step - loss: 0.2826 - acc: 0.9010 - val_loss: 0.2826 - val_acc: 0.9012\n",
            "Epoch 84/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 0.2824 - acc: 0.9010 - val_loss: 0.2824 - val_acc: 0.9013\n",
            "Epoch 85/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 0.2822 - acc: 0.9010 - val_loss: 0.2822 - val_acc: 0.9013\n",
            "Epoch 86/500\n",
            "50000/50000 [==============================] - 12s 233us/step - loss: 0.2819 - acc: 0.9010 - val_loss: 0.2819 - val_acc: 0.9013\n",
            "Epoch 87/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 0.2817 - acc: 0.9011 - val_loss: 0.2817 - val_acc: 0.9013\n",
            "Epoch 88/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.2815 - acc: 0.9011 - val_loss: 0.2815 - val_acc: 0.9014\n",
            "Epoch 89/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 0.2813 - acc: 0.9011 - val_loss: 0.2813 - val_acc: 0.9014\n",
            "Epoch 90/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 0.2811 - acc: 0.9011 - val_loss: 0.2811 - val_acc: 0.9015\n",
            "Epoch 91/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 0.2809 - acc: 0.9011 - val_loss: 0.2809 - val_acc: 0.9015\n",
            "Epoch 92/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 0.2807 - acc: 0.9011 - val_loss: 0.2807 - val_acc: 0.9015\n",
            "Epoch 93/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 0.2805 - acc: 0.9012 - val_loss: 0.2805 - val_acc: 0.9016\n",
            "Epoch 94/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 0.2803 - acc: 0.9012 - val_loss: 0.2804 - val_acc: 0.9016\n",
            "Epoch 95/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 0.2801 - acc: 0.9012 - val_loss: 0.2802 - val_acc: 0.9016\n",
            "Epoch 96/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 0.2799 - acc: 0.9012 - val_loss: 0.2800 - val_acc: 0.9016\n",
            "Epoch 97/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 0.2797 - acc: 0.9013 - val_loss: 0.2798 - val_acc: 0.9017\n",
            "Epoch 98/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 0.2796 - acc: 0.9013 - val_loss: 0.2796 - val_acc: 0.9017\n",
            "Epoch 99/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.2794 - acc: 0.9013 - val_loss: 0.2794 - val_acc: 0.9017\n",
            "Epoch 100/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 0.2792 - acc: 0.9013 - val_loss: 0.2792 - val_acc: 0.9016\n",
            "Epoch 101/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 0.2790 - acc: 0.9013 - val_loss: 0.2791 - val_acc: 0.9017\n",
            "Epoch 102/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 0.2788 - acc: 0.9013 - val_loss: 0.2789 - val_acc: 0.9017\n",
            "Epoch 103/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.2786 - acc: 0.9014 - val_loss: 0.2787 - val_acc: 0.9017\n",
            "Epoch 104/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 0.2785 - acc: 0.9014 - val_loss: 0.2785 - val_acc: 0.9017\n",
            "Epoch 105/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 0.2783 - acc: 0.9014 - val_loss: 0.2784 - val_acc: 0.9017\n",
            "Epoch 106/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 0.2781 - acc: 0.9015 - val_loss: 0.2782 - val_acc: 0.9018\n",
            "Epoch 107/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.2779 - acc: 0.9015 - val_loss: 0.2780 - val_acc: 0.9017\n",
            "Epoch 108/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.2778 - acc: 0.9015 - val_loss: 0.2779 - val_acc: 0.9017\n",
            "Epoch 109/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 0.2776 - acc: 0.9015 - val_loss: 0.2777 - val_acc: 0.9017\n",
            "Epoch 110/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 0.2774 - acc: 0.9016 - val_loss: 0.2775 - val_acc: 0.9018\n",
            "Epoch 111/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 0.2773 - acc: 0.9016 - val_loss: 0.2774 - val_acc: 0.9017\n",
            "Epoch 112/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.2771 - acc: 0.9017 - val_loss: 0.2772 - val_acc: 0.9018\n",
            "Epoch 113/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 0.2769 - acc: 0.9017 - val_loss: 0.2770 - val_acc: 0.9017\n",
            "Epoch 114/500\n",
            "50000/50000 [==============================] - 11s 230us/step - loss: 0.2768 - acc: 0.9017 - val_loss: 0.2769 - val_acc: 0.9018\n",
            "Epoch 115/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 0.2766 - acc: 0.9017 - val_loss: 0.2767 - val_acc: 0.9018\n",
            "Epoch 116/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 0.2765 - acc: 0.9017 - val_loss: 0.2766 - val_acc: 0.9019\n",
            "Epoch 117/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 0.2763 - acc: 0.9018 - val_loss: 0.2764 - val_acc: 0.9018\n",
            "Epoch 118/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 0.2762 - acc: 0.9018 - val_loss: 0.2763 - val_acc: 0.9018\n",
            "Epoch 119/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.2760 - acc: 0.9018 - val_loss: 0.2761 - val_acc: 0.9019\n",
            "Epoch 120/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 0.2759 - acc: 0.9018 - val_loss: 0.2760 - val_acc: 0.9019\n",
            "Epoch 121/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 0.2757 - acc: 0.9018 - val_loss: 0.2759 - val_acc: 0.9019\n",
            "Epoch 122/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 0.2756 - acc: 0.9019 - val_loss: 0.2757 - val_acc: 0.9019\n",
            "Epoch 123/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 0.2754 - acc: 0.9019 - val_loss: 0.2756 - val_acc: 0.9019\n",
            "Epoch 124/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 0.2753 - acc: 0.9019 - val_loss: 0.2754 - val_acc: 0.9020\n",
            "Epoch 125/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 0.2751 - acc: 0.9019 - val_loss: 0.2753 - val_acc: 0.9020\n",
            "Epoch 126/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 0.2750 - acc: 0.9019 - val_loss: 0.2752 - val_acc: 0.9020\n",
            "Epoch 127/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 0.2748 - acc: 0.9020 - val_loss: 0.2750 - val_acc: 0.9020\n",
            "Epoch 128/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 0.2747 - acc: 0.9020 - val_loss: 0.2749 - val_acc: 0.9020\n",
            "Epoch 129/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 0.2746 - acc: 0.9020 - val_loss: 0.2747 - val_acc: 0.9020\n",
            "Epoch 130/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 0.2744 - acc: 0.9020 - val_loss: 0.2746 - val_acc: 0.9020\n",
            "Epoch 131/500\n",
            "50000/50000 [==============================] - 11s 210us/step - loss: 0.2743 - acc: 0.9021 - val_loss: 0.2745 - val_acc: 0.9021\n",
            "Epoch 132/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 0.2742 - acc: 0.9021 - val_loss: 0.2744 - val_acc: 0.9020\n",
            "Epoch 133/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 0.2740 - acc: 0.9021 - val_loss: 0.2742 - val_acc: 0.9021\n",
            "Epoch 134/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 0.2739 - acc: 0.9021 - val_loss: 0.2741 - val_acc: 0.9021\n",
            "Epoch 135/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 0.2738 - acc: 0.9022 - val_loss: 0.2740 - val_acc: 0.9020\n",
            "Epoch 136/500\n",
            "50000/50000 [==============================] - 11s 210us/step - loss: 0.2736 - acc: 0.9021 - val_loss: 0.2738 - val_acc: 0.9021\n",
            "Epoch 137/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 0.2735 - acc: 0.9022 - val_loss: 0.2737 - val_acc: 0.9021\n",
            "Epoch 138/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 0.2734 - acc: 0.9022 - val_loss: 0.2736 - val_acc: 0.9021\n",
            "Epoch 139/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 0.2732 - acc: 0.9022 - val_loss: 0.2735 - val_acc: 0.9021\n",
            "Epoch 140/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 0.2731 - acc: 0.9022 - val_loss: 0.2733 - val_acc: 0.9021\n",
            "Epoch 141/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 0.2730 - acc: 0.9023 - val_loss: 0.2732 - val_acc: 0.9021\n",
            "Epoch 142/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 0.2729 - acc: 0.9023 - val_loss: 0.2731 - val_acc: 0.9022\n",
            "Epoch 143/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 0.2727 - acc: 0.9023 - val_loss: 0.2730 - val_acc: 0.9022\n",
            "Epoch 144/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.2726 - acc: 0.9023 - val_loss: 0.2728 - val_acc: 0.9021\n",
            "Epoch 145/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 0.2725 - acc: 0.9023 - val_loss: 0.2727 - val_acc: 0.9022\n",
            "Epoch 146/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 0.2723 - acc: 0.9024 - val_loss: 0.2726 - val_acc: 0.9022\n",
            "Epoch 147/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 0.2722 - acc: 0.9024 - val_loss: 0.2725 - val_acc: 0.9023\n",
            "Epoch 148/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 0.2721 - acc: 0.9024 - val_loss: 0.2724 - val_acc: 0.9023\n",
            "Epoch 149/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 0.2720 - acc: 0.9024 - val_loss: 0.2722 - val_acc: 0.9023\n",
            "Epoch 150/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 0.2719 - acc: 0.9024 - val_loss: 0.2721 - val_acc: 0.9023\n",
            "Epoch 151/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 0.2717 - acc: 0.9024 - val_loss: 0.2720 - val_acc: 0.9023\n",
            "Epoch 152/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 0.2716 - acc: 0.9025 - val_loss: 0.2719 - val_acc: 0.9023\n",
            "Epoch 153/500\n",
            "50000/50000 [==============================] - 10s 204us/step - loss: 0.2715 - acc: 0.9025 - val_loss: 0.2718 - val_acc: 0.9023\n",
            "Epoch 154/500\n",
            "50000/50000 [==============================] - 11s 210us/step - loss: 0.2714 - acc: 0.9025 - val_loss: 0.2717 - val_acc: 0.9023\n",
            "Epoch 155/500\n",
            "50000/50000 [==============================] - 10s 204us/step - loss: 0.2713 - acc: 0.9025 - val_loss: 0.2715 - val_acc: 0.9024\n",
            "Epoch 156/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 0.2711 - acc: 0.9026 - val_loss: 0.2714 - val_acc: 0.9024\n",
            "Epoch 157/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 0.2710 - acc: 0.9026 - val_loss: 0.2713 - val_acc: 0.9024\n",
            "Epoch 158/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 0.2709 - acc: 0.9026 - val_loss: 0.2712 - val_acc: 0.9024\n",
            "Epoch 159/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 0.2708 - acc: 0.9027 - val_loss: 0.2711 - val_acc: 0.9024\n",
            "Epoch 160/500\n",
            "50000/50000 [==============================] - 10s 202us/step - loss: 0.2707 - acc: 0.9027 - val_loss: 0.2710 - val_acc: 0.9024\n",
            "Epoch 161/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 0.2706 - acc: 0.9027 - val_loss: 0.2709 - val_acc: 0.9024\n",
            "Epoch 162/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 0.2705 - acc: 0.9027 - val_loss: 0.2708 - val_acc: 0.9024\n",
            "Epoch 163/500\n",
            "50000/50000 [==============================] - 10s 204us/step - loss: 0.2704 - acc: 0.9027 - val_loss: 0.2706 - val_acc: 0.9024\n",
            "Epoch 164/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 0.2702 - acc: 0.9027 - val_loss: 0.2705 - val_acc: 0.9024\n",
            "Epoch 165/500\n",
            "50000/50000 [==============================] - 10s 204us/step - loss: 0.2701 - acc: 0.9027 - val_loss: 0.2704 - val_acc: 0.9024\n",
            "Epoch 166/500\n",
            "50000/50000 [==============================] - 10s 204us/step - loss: 0.2700 - acc: 0.9028 - val_loss: 0.2703 - val_acc: 0.9024\n",
            "Epoch 167/500\n",
            "50000/50000 [==============================] - 10s 204us/step - loss: 0.2699 - acc: 0.9028 - val_loss: 0.2702 - val_acc: 0.9024\n",
            "Epoch 168/500\n",
            "50000/50000 [==============================] - 10s 202us/step - loss: 0.2698 - acc: 0.9028 - val_loss: 0.2701 - val_acc: 0.9025\n",
            "Epoch 169/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 0.2697 - acc: 0.9028 - val_loss: 0.2700 - val_acc: 0.9024\n",
            "Epoch 170/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 0.2696 - acc: 0.9028 - val_loss: 0.2699 - val_acc: 0.9024\n",
            "Epoch 171/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 0.2695 - acc: 0.9028 - val_loss: 0.2698 - val_acc: 0.9024\n",
            "Epoch 172/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 0.2694 - acc: 0.9029 - val_loss: 0.2697 - val_acc: 0.9025\n",
            "Epoch 173/500\n",
            "50000/50000 [==============================] - 10s 204us/step - loss: 0.2693 - acc: 0.9029 - val_loss: 0.2696 - val_acc: 0.9025\n",
            "Epoch 174/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 0.2692 - acc: 0.9029 - val_loss: 0.2695 - val_acc: 0.9025\n",
            "Epoch 175/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 0.2691 - acc: 0.9029 - val_loss: 0.2694 - val_acc: 0.9025\n",
            "Epoch 176/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 0.2690 - acc: 0.9030 - val_loss: 0.2693 - val_acc: 0.9025\n",
            "Epoch 177/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 0.2689 - acc: 0.9030 - val_loss: 0.2692 - val_acc: 0.9026\n",
            "Epoch 178/500\n",
            "50000/50000 [==============================] - 10s 204us/step - loss: 0.2688 - acc: 0.9030 - val_loss: 0.2691 - val_acc: 0.9026\n",
            "Epoch 179/500\n",
            "50000/50000 [==============================] - 10s 204us/step - loss: 0.2687 - acc: 0.9030 - val_loss: 0.2690 - val_acc: 0.9026\n",
            "Epoch 180/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 0.2686 - acc: 0.9030 - val_loss: 0.2689 - val_acc: 0.9026\n",
            "Epoch 181/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 0.2685 - acc: 0.9030 - val_loss: 0.2688 - val_acc: 0.9026\n",
            "Epoch 182/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 0.2684 - acc: 0.9031 - val_loss: 0.2687 - val_acc: 0.9027\n",
            "Epoch 183/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 0.2683 - acc: 0.9031 - val_loss: 0.2686 - val_acc: 0.9027\n",
            "Epoch 184/500\n",
            "50000/50000 [==============================] - 10s 202us/step - loss: 0.2682 - acc: 0.9031 - val_loss: 0.2685 - val_acc: 0.9029\n",
            "Epoch 185/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 0.2681 - acc: 0.9031 - val_loss: 0.2684 - val_acc: 0.9028\n",
            "Epoch 186/500\n",
            "50000/50000 [==============================] - 10s 201us/step - loss: 0.2680 - acc: 0.9032 - val_loss: 0.2683 - val_acc: 0.9029\n",
            "Epoch 187/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.2679 - acc: 0.9032 - val_loss: 0.2682 - val_acc: 0.9029\n",
            "Epoch 188/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 0.2678 - acc: 0.9032 - val_loss: 0.2681 - val_acc: 0.9029\n",
            "Epoch 189/500\n",
            "50000/50000 [==============================] - 10s 204us/step - loss: 0.2677 - acc: 0.9032 - val_loss: 0.2681 - val_acc: 0.9029\n",
            "Epoch 190/500\n",
            "50000/50000 [==============================] - 10s 202us/step - loss: 0.2676 - acc: 0.9033 - val_loss: 0.2679 - val_acc: 0.9030\n",
            "Epoch 191/500\n",
            "50000/50000 [==============================] - 10s 202us/step - loss: 0.2675 - acc: 0.9032 - val_loss: 0.2679 - val_acc: 0.9030\n",
            "Epoch 192/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 0.2674 - acc: 0.9033 - val_loss: 0.2678 - val_acc: 0.9031\n",
            "Epoch 193/500\n",
            "50000/50000 [==============================] - 10s 201us/step - loss: 0.2673 - acc: 0.9033 - val_loss: 0.2677 - val_acc: 0.9030\n",
            "Epoch 194/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 0.2672 - acc: 0.9033 - val_loss: 0.2676 - val_acc: 0.9030\n",
            "Epoch 195/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 0.2671 - acc: 0.9033 - val_loss: 0.2675 - val_acc: 0.9031\n",
            "Epoch 196/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 0.2670 - acc: 0.9033 - val_loss: 0.2674 - val_acc: 0.9031\n",
            "Epoch 197/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 0.2669 - acc: 0.9034 - val_loss: 0.2673 - val_acc: 0.9031\n",
            "Epoch 198/500\n",
            "50000/50000 [==============================] - 10s 204us/step - loss: 0.2669 - acc: 0.9033 - val_loss: 0.2672 - val_acc: 0.9032\n",
            "Epoch 199/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 0.2668 - acc: 0.9034 - val_loss: 0.2671 - val_acc: 0.9032\n",
            "Epoch 200/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 0.2667 - acc: 0.9034 - val_loss: 0.2670 - val_acc: 0.9033\n",
            "Epoch 201/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 0.2666 - acc: 0.9035 - val_loss: 0.2669 - val_acc: 0.9032\n",
            "Epoch 202/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 0.2665 - acc: 0.9034 - val_loss: 0.2669 - val_acc: 0.9032\n",
            "Epoch 203/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 0.2664 - acc: 0.9035 - val_loss: 0.2668 - val_acc: 0.9033\n",
            "Epoch 204/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 0.2663 - acc: 0.9035 - val_loss: 0.2667 - val_acc: 0.9033\n",
            "Epoch 205/500\n",
            "50000/50000 [==============================] - 11s 210us/step - loss: 0.2662 - acc: 0.9035 - val_loss: 0.2666 - val_acc: 0.9033\n",
            "Epoch 206/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 0.2661 - acc: 0.9036 - val_loss: 0.2665 - val_acc: 0.9033\n",
            "Epoch 207/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 0.2660 - acc: 0.9036 - val_loss: 0.2664 - val_acc: 0.9034\n",
            "Epoch 208/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 0.2660 - acc: 0.9036 - val_loss: 0.2663 - val_acc: 0.9034\n",
            "Epoch 209/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 0.2659 - acc: 0.9036 - val_loss: 0.2663 - val_acc: 0.9035\n",
            "Epoch 210/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 0.2658 - acc: 0.9036 - val_loss: 0.2662 - val_acc: 0.9035\n",
            "Epoch 211/500\n",
            "50000/50000 [==============================] - 11s 210us/step - loss: 0.2657 - acc: 0.9036 - val_loss: 0.2661 - val_acc: 0.9034\n",
            "Epoch 212/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 0.2656 - acc: 0.9036 - val_loss: 0.2660 - val_acc: 0.9036\n",
            "Epoch 213/500\n",
            "50000/50000 [==============================] - 10s 210us/step - loss: 0.2655 - acc: 0.9037 - val_loss: 0.2659 - val_acc: 0.9035\n",
            "Epoch 214/500\n",
            "50000/50000 [==============================] - 10s 210us/step - loss: 0.2654 - acc: 0.9037 - val_loss: 0.2658 - val_acc: 0.9035\n",
            "Epoch 215/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 0.2653 - acc: 0.9037 - val_loss: 0.2658 - val_acc: 0.9036\n",
            "Epoch 216/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 0.2653 - acc: 0.9038 - val_loss: 0.2657 - val_acc: 0.9036\n",
            "Epoch 217/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 0.2652 - acc: 0.9038 - val_loss: 0.2656 - val_acc: 0.9036\n",
            "Epoch 218/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 0.2651 - acc: 0.9038 - val_loss: 0.2655 - val_acc: 0.9036\n",
            "Epoch 219/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 0.2650 - acc: 0.9038 - val_loss: 0.2654 - val_acc: 0.9036\n",
            "Epoch 220/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 0.2649 - acc: 0.9038 - val_loss: 0.2653 - val_acc: 0.9036\n",
            "Epoch 221/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 0.2648 - acc: 0.9038 - val_loss: 0.2653 - val_acc: 0.9037\n",
            "Epoch 222/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 0.2648 - acc: 0.9039 - val_loss: 0.2652 - val_acc: 0.9036\n",
            "Epoch 223/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 0.2647 - acc: 0.9038 - val_loss: 0.2651 - val_acc: 0.9037\n",
            "Epoch 224/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 0.2646 - acc: 0.9039 - val_loss: 0.2650 - val_acc: 0.9037\n",
            "Epoch 225/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 0.2645 - acc: 0.9038 - val_loss: 0.2649 - val_acc: 0.9036\n",
            "Epoch 226/500\n",
            "50000/50000 [==============================] - 10s 200us/step - loss: 0.2644 - acc: 0.9039 - val_loss: 0.2649 - val_acc: 0.9036\n",
            "Epoch 227/500\n",
            "50000/50000 [==============================] - 10s 204us/step - loss: 0.2643 - acc: 0.9039 - val_loss: 0.2648 - val_acc: 0.9036\n",
            "Epoch 228/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 0.2643 - acc: 0.9039 - val_loss: 0.2647 - val_acc: 0.9036\n",
            "Epoch 229/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 0.2642 - acc: 0.9039 - val_loss: 0.2646 - val_acc: 0.9037\n",
            "Epoch 230/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 0.2641 - acc: 0.9039 - val_loss: 0.2646 - val_acc: 0.9037\n",
            "Epoch 231/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 0.2640 - acc: 0.9040 - val_loss: 0.2645 - val_acc: 0.9037\n",
            "Epoch 232/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 0.2639 - acc: 0.9040 - val_loss: 0.2644 - val_acc: 0.9037\n",
            "Epoch 233/500\n",
            "50000/50000 [==============================] - 10s 204us/step - loss: 0.2639 - acc: 0.9040 - val_loss: 0.2643 - val_acc: 0.9037\n",
            "Epoch 234/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 0.2638 - acc: 0.9040 - val_loss: 0.2642 - val_acc: 0.9037\n",
            "Epoch 235/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 0.2637 - acc: 0.9040 - val_loss: 0.2642 - val_acc: 0.9038\n",
            "Epoch 236/500\n",
            "50000/50000 [==============================] - 10s 201us/step - loss: 0.2636 - acc: 0.9040 - val_loss: 0.2641 - val_acc: 0.9037\n",
            "Epoch 237/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 0.2635 - acc: 0.9040 - val_loss: 0.2640 - val_acc: 0.9038\n",
            "Epoch 238/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 0.2635 - acc: 0.9041 - val_loss: 0.2639 - val_acc: 0.9038\n",
            "Epoch 239/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 0.2634 - acc: 0.9041 - val_loss: 0.2638 - val_acc: 0.9038\n",
            "Epoch 240/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 0.2633 - acc: 0.9041 - val_loss: 0.2638 - val_acc: 0.9039\n",
            "Epoch 241/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 0.2632 - acc: 0.9041 - val_loss: 0.2637 - val_acc: 0.9038\n",
            "Epoch 242/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 0.2631 - acc: 0.9042 - val_loss: 0.2636 - val_acc: 0.9039\n",
            "Epoch 243/500\n",
            "50000/50000 [==============================] - 17s 340us/step - loss: 0.2631 - acc: 0.9042 - val_loss: 0.2635 - val_acc: 0.9039\n",
            "Epoch 244/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 0.2630 - acc: 0.9041 - val_loss: 0.2635 - val_acc: 0.9039\n",
            "Epoch 245/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 0.2629 - acc: 0.9042 - val_loss: 0.2634 - val_acc: 0.9039\n",
            "Epoch 246/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 0.2628 - acc: 0.9042 - val_loss: 0.2633 - val_acc: 0.9039\n",
            "Epoch 247/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 0.2627 - acc: 0.9042 - val_loss: 0.2632 - val_acc: 0.9040\n",
            "Epoch 248/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 0.2627 - acc: 0.9043 - val_loss: 0.2631 - val_acc: 0.9040\n",
            "Epoch 249/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 0.2626 - acc: 0.9043 - val_loss: 0.2631 - val_acc: 0.9040\n",
            "Epoch 250/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 0.2625 - acc: 0.9043 - val_loss: 0.2630 - val_acc: 0.9040\n",
            "Epoch 251/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 0.2624 - acc: 0.9043 - val_loss: 0.2629 - val_acc: 0.9040\n",
            "Epoch 252/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 0.2624 - acc: 0.9043 - val_loss: 0.2628 - val_acc: 0.9041\n",
            "Epoch 253/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 0.2623 - acc: 0.9043 - val_loss: 0.2628 - val_acc: 0.9041\n",
            "Epoch 254/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 0.2622 - acc: 0.9043 - val_loss: 0.2627 - val_acc: 0.9041\n",
            "Epoch 255/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 0.2621 - acc: 0.9043 - val_loss: 0.2626 - val_acc: 0.9042\n",
            "Epoch 256/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 0.2620 - acc: 0.9044 - val_loss: 0.2626 - val_acc: 0.9042\n",
            "Epoch 257/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 0.2620 - acc: 0.9044 - val_loss: 0.2625 - val_acc: 0.9042\n",
            "Epoch 258/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.2619 - acc: 0.9044 - val_loss: 0.2624 - val_acc: 0.9042\n",
            "Epoch 259/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 0.2618 - acc: 0.9044 - val_loss: 0.2623 - val_acc: 0.9043\n",
            "Epoch 260/500\n",
            "50000/50000 [==============================] - 10s 210us/step - loss: 0.2617 - acc: 0.9044 - val_loss: 0.2622 - val_acc: 0.9043\n",
            "Epoch 261/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 0.2617 - acc: 0.9045 - val_loss: 0.2622 - val_acc: 0.9042\n",
            "Epoch 262/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 0.2616 - acc: 0.9044 - val_loss: 0.2621 - val_acc: 0.9043\n",
            "Epoch 263/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 0.2615 - acc: 0.9045 - val_loss: 0.2620 - val_acc: 0.9044\n",
            "Epoch 264/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 0.2614 - acc: 0.9045 - val_loss: 0.2620 - val_acc: 0.9044\n",
            "Epoch 265/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 0.2614 - acc: 0.9045 - val_loss: 0.2619 - val_acc: 0.9044\n",
            "Epoch 266/500\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 0.2613 - acc: 0.9045 - val_loss: 0.2618 - val_acc: 0.9044\n",
            "Epoch 267/500\n",
            "50000/50000 [==============================] - 12s 238us/step - loss: 0.2612 - acc: 0.9045 - val_loss: 0.2617 - val_acc: 0.9044\n",
            "Epoch 268/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.2611 - acc: 0.9045 - val_loss: 0.2616 - val_acc: 0.9044\n",
            "Epoch 269/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 0.2611 - acc: 0.9046 - val_loss: 0.2616 - val_acc: 0.9045\n",
            "Epoch 270/500\n",
            "50000/50000 [==============================] - 12s 237us/step - loss: 0.2610 - acc: 0.9046 - val_loss: 0.2615 - val_acc: 0.9044\n",
            "Epoch 271/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 0.2609 - acc: 0.9046 - val_loss: 0.2614 - val_acc: 0.9045\n",
            "Epoch 272/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 0.2608 - acc: 0.9046 - val_loss: 0.2614 - val_acc: 0.9046\n",
            "Epoch 273/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 0.2608 - acc: 0.9047 - val_loss: 0.2613 - val_acc: 0.9046\n",
            "Epoch 274/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 0.2607 - acc: 0.9047 - val_loss: 0.2612 - val_acc: 0.9045\n",
            "Epoch 275/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 0.2606 - acc: 0.9046 - val_loss: 0.2611 - val_acc: 0.9046\n",
            "Epoch 276/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 0.2605 - acc: 0.9047 - val_loss: 0.2611 - val_acc: 0.9046\n",
            "Epoch 277/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 0.2605 - acc: 0.9047 - val_loss: 0.2610 - val_acc: 0.9046\n",
            "Epoch 278/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 0.2604 - acc: 0.9047 - val_loss: 0.2610 - val_acc: 0.9046\n",
            "Epoch 279/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 0.2603 - acc: 0.9048 - val_loss: 0.2609 - val_acc: 0.9046\n",
            "Epoch 280/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 0.2602 - acc: 0.9047 - val_loss: 0.2608 - val_acc: 0.9046\n",
            "Epoch 281/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 0.2602 - acc: 0.9048 - val_loss: 0.2607 - val_acc: 0.9047\n",
            "Epoch 282/500\n",
            "50000/50000 [==============================] - 11s 210us/step - loss: 0.2601 - acc: 0.9048 - val_loss: 0.2606 - val_acc: 0.9047\n",
            "Epoch 283/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 0.2600 - acc: 0.9048 - val_loss: 0.2606 - val_acc: 0.9047\n",
            "Epoch 284/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 0.2600 - acc: 0.9048 - val_loss: 0.2605 - val_acc: 0.9048\n",
            "Epoch 285/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 0.2599 - acc: 0.9048 - val_loss: 0.2604 - val_acc: 0.9048\n",
            "Epoch 286/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 0.2598 - acc: 0.9048 - val_loss: 0.2604 - val_acc: 0.9048\n",
            "Epoch 287/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 0.2597 - acc: 0.9049 - val_loss: 0.2603 - val_acc: 0.9050\n",
            "Epoch 288/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 0.2597 - acc: 0.9048 - val_loss: 0.2602 - val_acc: 0.9049\n",
            "Epoch 289/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 0.2596 - acc: 0.9048 - val_loss: 0.2602 - val_acc: 0.9049\n",
            "Epoch 290/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 0.2595 - acc: 0.9049 - val_loss: 0.2601 - val_acc: 0.9049\n",
            "Epoch 291/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 0.2595 - acc: 0.9049 - val_loss: 0.2600 - val_acc: 0.9050\n",
            "Epoch 292/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 0.2594 - acc: 0.9049 - val_loss: 0.2600 - val_acc: 0.9050\n",
            "Epoch 293/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 0.2593 - acc: 0.9050 - val_loss: 0.2599 - val_acc: 0.9050\n",
            "Epoch 294/500\n",
            "50000/50000 [==============================] - 12s 235us/step - loss: 0.2592 - acc: 0.9050 - val_loss: 0.2598 - val_acc: 0.9051\n",
            "Epoch 295/500\n",
            "50000/50000 [==============================] - 12s 235us/step - loss: 0.2592 - acc: 0.9050 - val_loss: 0.2598 - val_acc: 0.9050\n",
            "Epoch 296/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 0.2591 - acc: 0.9050 - val_loss: 0.2597 - val_acc: 0.9051\n",
            "Epoch 297/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 0.2590 - acc: 0.9050 - val_loss: 0.2596 - val_acc: 0.9051\n",
            "Epoch 298/500\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.2590 - acc: 0.9051 - val_loss: 0.2596 - val_acc: 0.9052\n",
            "Epoch 299/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 0.2589 - acc: 0.9050 - val_loss: 0.2595 - val_acc: 0.9051\n",
            "Epoch 300/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 0.2588 - acc: 0.9050 - val_loss: 0.2594 - val_acc: 0.9051\n",
            "Epoch 301/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 0.2588 - acc: 0.9051 - val_loss: 0.2594 - val_acc: 0.9051\n",
            "Epoch 302/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 0.2587 - acc: 0.9051 - val_loss: 0.2593 - val_acc: 0.9052\n",
            "Epoch 303/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 0.2586 - acc: 0.9051 - val_loss: 0.2592 - val_acc: 0.9052\n",
            "Epoch 304/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 0.2585 - acc: 0.9051 - val_loss: 0.2592 - val_acc: 0.9051\n",
            "Epoch 305/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 0.2585 - acc: 0.9051 - val_loss: 0.2591 - val_acc: 0.9053\n",
            "Epoch 306/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 0.2584 - acc: 0.9051 - val_loss: 0.2590 - val_acc: 0.9053\n",
            "Epoch 307/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 0.2583 - acc: 0.9051 - val_loss: 0.2589 - val_acc: 0.9052\n",
            "Epoch 308/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 0.2583 - acc: 0.9052 - val_loss: 0.2589 - val_acc: 0.9054\n",
            "Epoch 309/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 0.2582 - acc: 0.9051 - val_loss: 0.2588 - val_acc: 0.9052\n",
            "Epoch 310/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 0.2581 - acc: 0.9052 - val_loss: 0.2588 - val_acc: 0.9053\n",
            "Epoch 311/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 0.2581 - acc: 0.9052 - val_loss: 0.2587 - val_acc: 0.9053\n",
            "Epoch 312/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 0.2580 - acc: 0.9052 - val_loss: 0.2586 - val_acc: 0.9052\n",
            "Epoch 313/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 0.2579 - acc: 0.9052 - val_loss: 0.2586 - val_acc: 0.9052\n",
            "Epoch 314/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.2579 - acc: 0.9052 - val_loss: 0.2585 - val_acc: 0.9055\n",
            "Epoch 315/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 0.2578 - acc: 0.9053 - val_loss: 0.2584 - val_acc: 0.9053\n",
            "Epoch 316/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 0.2577 - acc: 0.9053 - val_loss: 0.2584 - val_acc: 0.9054\n",
            "Epoch 317/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 0.2577 - acc: 0.9053 - val_loss: 0.2583 - val_acc: 0.9053\n",
            "Epoch 318/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 0.2576 - acc: 0.9053 - val_loss: 0.2582 - val_acc: 0.9054\n",
            "Epoch 319/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 0.2575 - acc: 0.9053 - val_loss: 0.2582 - val_acc: 0.9054\n",
            "Epoch 320/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 0.2575 - acc: 0.9053 - val_loss: 0.2581 - val_acc: 0.9053\n",
            "Epoch 321/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 0.2574 - acc: 0.9053 - val_loss: 0.2580 - val_acc: 0.9053\n",
            "Epoch 322/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 0.2573 - acc: 0.9054 - val_loss: 0.2580 - val_acc: 0.9053\n",
            "Epoch 323/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 0.2573 - acc: 0.9054 - val_loss: 0.2579 - val_acc: 0.9054\n",
            "Epoch 324/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 0.2572 - acc: 0.9054 - val_loss: 0.2579 - val_acc: 0.9054\n",
            "Epoch 325/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 0.2571 - acc: 0.9054 - val_loss: 0.2578 - val_acc: 0.9055\n",
            "Epoch 326/500\n",
            "50000/50000 [==============================] - 12s 235us/step - loss: 0.2571 - acc: 0.9054 - val_loss: 0.2577 - val_acc: 0.9054\n",
            "Epoch 327/500\n",
            "50000/50000 [==============================] - 12s 232us/step - loss: 0.2570 - acc: 0.9054 - val_loss: 0.2577 - val_acc: 0.9055\n",
            "Epoch 328/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 0.2569 - acc: 0.9055 - val_loss: 0.2576 - val_acc: 0.9055\n",
            "Epoch 329/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 0.2569 - acc: 0.9054 - val_loss: 0.2575 - val_acc: 0.9055\n",
            "Epoch 330/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 0.2568 - acc: 0.9054 - val_loss: 0.2575 - val_acc: 0.9054\n",
            "Epoch 331/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.2567 - acc: 0.9054 - val_loss: 0.2574 - val_acc: 0.9054\n",
            "Epoch 332/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 0.2567 - acc: 0.9055 - val_loss: 0.2574 - val_acc: 0.9054\n",
            "Epoch 333/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 0.2566 - acc: 0.9055 - val_loss: 0.2573 - val_acc: 0.9054\n",
            "Epoch 334/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 0.2566 - acc: 0.9055 - val_loss: 0.2572 - val_acc: 0.9055\n",
            "Epoch 335/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 0.2565 - acc: 0.9055 - val_loss: 0.2571 - val_acc: 0.9055\n",
            "Epoch 336/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 0.2564 - acc: 0.9055 - val_loss: 0.2571 - val_acc: 0.9055\n",
            "Epoch 337/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 0.2564 - acc: 0.9055 - val_loss: 0.2570 - val_acc: 0.9056\n",
            "Epoch 338/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 0.2563 - acc: 0.9056 - val_loss: 0.2570 - val_acc: 0.9056\n",
            "Epoch 339/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 0.2562 - acc: 0.9056 - val_loss: 0.2569 - val_acc: 0.9056\n",
            "Epoch 340/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 0.2562 - acc: 0.9056 - val_loss: 0.2569 - val_acc: 0.9055\n",
            "Epoch 341/500\n",
            "50000/50000 [==============================] - 12s 230us/step - loss: 0.2561 - acc: 0.9056 - val_loss: 0.2568 - val_acc: 0.9056\n",
            "Epoch 342/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 0.2560 - acc: 0.9056 - val_loss: 0.2567 - val_acc: 0.9056\n",
            "Epoch 343/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 0.2560 - acc: 0.9056 - val_loss: 0.2567 - val_acc: 0.9056\n",
            "Epoch 344/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 0.2559 - acc: 0.9056 - val_loss: 0.2566 - val_acc: 0.9056\n",
            "Epoch 345/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 0.2559 - acc: 0.9057 - val_loss: 0.2565 - val_acc: 0.9056\n",
            "Epoch 346/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 0.2558 - acc: 0.9057 - val_loss: 0.2565 - val_acc: 0.9057\n",
            "Epoch 347/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 0.2557 - acc: 0.9057 - val_loss: 0.2564 - val_acc: 0.9056\n",
            "Epoch 348/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 0.2557 - acc: 0.9057 - val_loss: 0.2564 - val_acc: 0.9057\n",
            "Epoch 349/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 0.2556 - acc: 0.9057 - val_loss: 0.2563 - val_acc: 0.9057\n",
            "Epoch 350/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 0.2555 - acc: 0.9057 - val_loss: 0.2562 - val_acc: 0.9057\n",
            "Epoch 351/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 0.2555 - acc: 0.9057 - val_loss: 0.2562 - val_acc: 0.9057\n",
            "Epoch 352/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 0.2554 - acc: 0.9057 - val_loss: 0.2561 - val_acc: 0.9057\n",
            "Epoch 353/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 0.2554 - acc: 0.9057 - val_loss: 0.2561 - val_acc: 0.9057\n",
            "Epoch 354/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 0.2553 - acc: 0.9057 - val_loss: 0.2560 - val_acc: 0.9057\n",
            "Epoch 355/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 0.2552 - acc: 0.9057 - val_loss: 0.2559 - val_acc: 0.9057\n",
            "Epoch 356/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 0.2552 - acc: 0.9058 - val_loss: 0.2559 - val_acc: 0.9057\n",
            "Epoch 357/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 0.2551 - acc: 0.9058 - val_loss: 0.2558 - val_acc: 0.9058\n",
            "Epoch 358/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 0.2550 - acc: 0.9058 - val_loss: 0.2558 - val_acc: 0.9058\n",
            "Epoch 359/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 0.2550 - acc: 0.9058 - val_loss: 0.2557 - val_acc: 0.9058\n",
            "Epoch 360/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 0.2549 - acc: 0.9058 - val_loss: 0.2556 - val_acc: 0.9059\n",
            "Epoch 361/500\n",
            "50000/50000 [==============================] - 12s 233us/step - loss: 0.2549 - acc: 0.9058 - val_loss: 0.2556 - val_acc: 0.9058\n",
            "Epoch 362/500\n",
            "50000/50000 [==============================] - 12s 232us/step - loss: 0.2548 - acc: 0.9058 - val_loss: 0.2555 - val_acc: 0.9058\n",
            "Epoch 363/500\n",
            "50000/50000 [==============================] - 12s 233us/step - loss: 0.2547 - acc: 0.9059 - val_loss: 0.2555 - val_acc: 0.9058\n",
            "Epoch 364/500\n",
            "50000/50000 [==============================] - 12s 239us/step - loss: 0.2547 - acc: 0.9059 - val_loss: 0.2554 - val_acc: 0.9059\n",
            "Epoch 365/500\n",
            "50000/50000 [==============================] - 12s 234us/step - loss: 0.2546 - acc: 0.9059 - val_loss: 0.2553 - val_acc: 0.9059\n",
            "Epoch 366/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 0.2546 - acc: 0.9059 - val_loss: 0.2553 - val_acc: 0.9058\n",
            "Epoch 367/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 0.2545 - acc: 0.9059 - val_loss: 0.2552 - val_acc: 0.9059\n",
            "Epoch 368/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 0.2544 - acc: 0.9059 - val_loss: 0.2552 - val_acc: 0.9060\n",
            "Epoch 369/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 0.2544 - acc: 0.9059 - val_loss: 0.2551 - val_acc: 0.9059\n",
            "Epoch 370/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.2543 - acc: 0.9060 - val_loss: 0.2550 - val_acc: 0.9059\n",
            "Epoch 371/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 0.2543 - acc: 0.9059 - val_loss: 0.2550 - val_acc: 0.9060\n",
            "Epoch 372/500\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 0.2542 - acc: 0.9059 - val_loss: 0.2549 - val_acc: 0.9059\n",
            "Epoch 373/500\n",
            "50000/50000 [==============================] - 10s 204us/step - loss: 0.2541 - acc: 0.9060 - val_loss: 0.2549 - val_acc: 0.9060\n",
            "Epoch 374/500\n",
            "50000/50000 [==============================] - 10s 200us/step - loss: 0.2541 - acc: 0.9060 - val_loss: 0.2548 - val_acc: 0.9060\n",
            "Epoch 375/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 0.2540 - acc: 0.9060 - val_loss: 0.2548 - val_acc: 0.9060\n",
            "Epoch 376/500\n",
            "50000/50000 [==============================] - 10s 210us/step - loss: 0.2540 - acc: 0.9060 - val_loss: 0.2547 - val_acc: 0.9060\n",
            "Epoch 377/500\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 0.2539 - acc: 0.9061 - val_loss: 0.2547 - val_acc: 0.9059\n",
            "Epoch 378/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 0.2538 - acc: 0.9060 - val_loss: 0.2546 - val_acc: 0.9061\n",
            "Epoch 379/500\n",
            "50000/50000 [==============================] - 10s 210us/step - loss: 0.2538 - acc: 0.9060 - val_loss: 0.2545 - val_acc: 0.9061\n",
            "Epoch 380/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 0.2537 - acc: 0.9061 - val_loss: 0.2545 - val_acc: 0.9061\n",
            "Epoch 381/500\n",
            "50000/50000 [==============================] - 10s 203us/step - loss: 0.2537 - acc: 0.9061 - val_loss: 0.2544 - val_acc: 0.9061\n",
            "Epoch 382/500\n",
            "50000/50000 [==============================] - 10s 202us/step - loss: 0.2536 - acc: 0.9061 - val_loss: 0.2544 - val_acc: 0.9061\n",
            "Epoch 383/500\n",
            " 8960/50000 [====>.........................] - ETA: 7s - loss: 0.2535 - acc: 0.9064Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e80gd7nnOA12",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "47a7de26-b2a9-4787-df3e-b2d9ef488a35"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# 以視覺畫方式檢視訓練過程\n",
        "\n",
        "train_loss = model.history.history[\"loss\"]\n",
        "valid_loss = model.history.history[\"val_loss\"]\n",
        "\n",
        "train_acc = model.history.history[\"acc\"]\n",
        "valid_acc = model.history.history[\"val_acc\"]\n",
        "\n",
        "plt.plot(range(len(train_loss)), train_loss, label=\"train loss\")\n",
        "plt.plot(range(len(valid_loss)), valid_loss, label=\"valid loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Loss\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(range(len(train_acc)), train_acc, label=\"train accuracy\")\n",
        "plt.plot(range(len(valid_acc)), valid_acc, label=\"valid accuracy\")\n",
        "plt.legend()\n",
        "plt.title(\"Accuracy\")\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npP4H0qRlZPQJZV8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}